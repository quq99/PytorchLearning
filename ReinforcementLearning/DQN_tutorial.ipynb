{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this tutorial is to use Pytorch to train a Deep Q Learning(DQN) agent on the `CartPole-v0` task from the OpenAI Gym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T18:58:46.676622Z",
     "start_time": "2019-06-12T18:58:45.834900Z"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T18:58:47.350205Z",
     "start_time": "2019-06-12T18:58:46.678599Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T18:58:48.148627Z",
     "start_time": "2019-06-12T18:58:47.352503Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianqu/anaconda3/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\").unwrapped\n",
    "\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "plt.ion()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experience replay will help us to handle two things:\n",
    "* Avoid forgetting previous experiences.\n",
    "* Reduce correlations between experiences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to classes:\n",
    "\n",
    "* `Transition` - a tuple representing a single transition in our environment. It maps (state, action) pairs to their (next_state, reward)\n",
    "* `ReplayMemory` - a cyclic buffer of bounded size that holds the transitions observed recently. It also implement a `.sample()` method for selecting a random batch of transitions for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T18:58:48.154170Z",
     "start_time": "2019-06-12T18:58:48.150519Z"
    }
   },
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                       ('state', 'action', 'next_state', 'reward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T18:58:48.164672Z",
     "start_time": "2019-06-12T18:58:48.156944Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        \n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position+1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Q-network would be a convolutional neural network that takes in the difference between the current and previous screen patches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T18:58:48.176596Z",
     "start_time": "2019-06-12T18:58:48.168474Z"
    }
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3,16,kernel_size=5,stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16,32,kernel_size=5,stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32,32,kernel_size=5,stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        def conv2d_size_out(size, kernel_size=5, stride=2):\n",
    "            # calculate the output size of convolutional layer\n",
    "            return (size - kernel_size) // stride + 1\n",
    "        \n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_size = convw * convh * 32\n",
    "        \n",
    "        self.head = nn.Linear(linear_size, outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        out = self.head(x.view(x.size(0),-1)) # x.size(0) is batch size\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It use `torchvision.transform` to compose image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:02:31.257419Z",
     "start_time": "2019-06-12T19:02:30.999802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_cart_location:  589\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first resize\n",
    "resize = T.Compose([T.ToPILImage(),\n",
    "                   T.Resize(40, interpolation=Image.CUBIC),\n",
    "                   T.ToTensor()])\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return_val = int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "    print(\"get_cart_location: \", return_val)\n",
    "    return return_val\n",
    "\n",
    "def get_screen():\n",
    "    # return screen requested by gym is 400*600*3\n",
    "    \n",
    "    # first change to torch order channel*height*width\n",
    "    screen = env.render(mode=\"rgb_array\").transpose((2, 0 ,1))\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    # in cartpole-v0, we can cut off the top and bottom of the screen\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height*0.8)]\n",
    "    # now cut width\n",
    "    view_width = int(screen_width*0.6)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "    if cart_location < view_width//2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width)//2:\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width//2,\n",
    "                           cart_location + view_width//2)\n",
    "    screen = screen[:, :, slice_range]\n",
    "    \n",
    "    # conver to float, rescale to 0-1, to tensor, to device\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    screen = resize(screen).unsqueeze(0).to(device)\n",
    "    env.close()\n",
    "    return screen\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1,2,0).numpy(),\n",
    "          interpolation='none')\n",
    "plt.title('example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:00:03.315733Z",
     "start_time": "2019-06-12T19:00:03.306526Z"
    }
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:00:26.012997Z",
     "start_time": "2019-06-12T19:00:26.008810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01855836,  0.01816463, -0.02781037,  0.00611009])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
