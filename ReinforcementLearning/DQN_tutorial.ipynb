{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this tutorial is to use Pytorch to train a Deep Q Learning(DQN) agent on the `CartPole-v0` task from the OpenAI Gym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:09:53.695695Z",
     "start_time": "2019-06-12T19:09:53.337941Z"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:09:53.915151Z",
     "start_time": "2019-06-12T19:09:53.697800Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:09:54.181767Z",
     "start_time": "2019-06-12T19:09:53.918311Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianqu/anaconda3/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\").unwrapped\n",
    "\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "plt.ion()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experience replay will help us to handle two things:\n",
    "* Avoid forgetting previous experiences.\n",
    "* Reduce correlations between experiences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to classes:\n",
    "\n",
    "* `Transition` - a tuple representing a single transition in our environment. It maps (state, action) pairs to their (next_state, reward)\n",
    "* `ReplayMemory` - a cyclic buffer of bounded size that holds the transitions observed recently. It also implement a `.sample()` method for selecting a random batch of transitions for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:09:54.187051Z",
     "start_time": "2019-06-12T19:09:54.183588Z"
    }
   },
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                       ('state', 'action', 'next_state', 'reward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:09:54.195334Z",
     "start_time": "2019-06-12T19:09:54.189117Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        \n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position+1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Q-network would be a convolutional neural network that takes in the difference between the current and previous screen patches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:09:54.205196Z",
     "start_time": "2019-06-12T19:09:54.197171Z"
    }
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3,16,kernel_size=5,stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16,32,kernel_size=5,stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32,32,kernel_size=5,stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        def conv2d_size_out(size, kernel_size=5, stride=2):\n",
    "            # calculate the output size of convolutional layer\n",
    "            return (size - kernel_size) // stride + 1\n",
    "        \n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_size = convw * convh * 32\n",
    "        \n",
    "        self.head = nn.Linear(linear_size, outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        out = self.head(x.view(x.size(0),-1)) # x.size(0) is batch size\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It use `torchvision.transform` to compose image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:19:11.637460Z",
     "start_time": "2019-06-12T19:19:11.404638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first resize\n",
    "resize = T.Compose([T.ToPILImage(),\n",
    "                   T.Resize(40, interpolation=Image.CUBIC),\n",
    "                   T.ToTensor()])\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return_val = int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "    #print(\"get_cart_location: \", return_val)\n",
    "    #print(\"scale\", scale)\n",
    "    #print(\"screen_width\", screen_width)\n",
    "    return return_val\n",
    "\n",
    "def get_screen():\n",
    "    # return screen requested by gym is 400*600*3\n",
    "    \n",
    "    # first change to torch order channel*height*width\n",
    "    screen = env.render(mode=\"rgb_array\").transpose((2, 0 ,1))\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    # in cartpole-v0, we can cut off the top and bottom of the screen\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height*0.8)]\n",
    "    # now cut width\n",
    "    view_width = int(screen_width*0.6)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "    # | --- | ---- | --- |\n",
    "    #  0.3.   0.4.   0.3. \n",
    "    if cart_location < view_width//2:\n",
    "        slice_range = slice(view_width) # start 0 end view_width\n",
    "    elif cart_location > (screen_width - view_width//2):\n",
    "        # act like list [-3:], get right part view_width length\n",
    "        slice_range = slice(-view_width, None) \n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width//2,\n",
    "                           cart_location + view_width//2)\n",
    "    screen = screen[:, :, slice_range]\n",
    "    \n",
    "    # conver to float, rescale to 0-1, to tensor, to device\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    screen = resize(screen).unsqueeze(0).to(device)\n",
    "    \n",
    "    return screen\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1,2,0).numpy(),\n",
    "          interpolation='none')\n",
    "plt.title('example extracted screen')\n",
    "plt.show()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:09:54.964708Z",
     "start_time": "2019-06-12T19:09:54.959778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02870912,  0.00937056, -0.03623778,  0.0379286 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
