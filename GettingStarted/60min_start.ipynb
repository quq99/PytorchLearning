{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is:\n",
    "1. understand basic tensor in Pytorch and understand neural networks\n",
    "2. train a simple neural network using Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. a replacement of numpy\n",
    "2. a deep learning platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.839861Z",
     "start_time": "2019-05-26T13:40:12.347354Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construct matrix uninitialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.858371Z",
     "start_time": "2019-05-26T13:40:12.841606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[                                0.0000,\n",
      "                                        -2.0000,\n",
      "                             -721782964224.0000,\n",
      "                               -8592027648.0000,\n",
      "                                         0.0000],\n",
      "        [                                0.0000,\n",
      "                                         0.0000,\n",
      "                                         0.0000,\n",
      "         -70741735374327006795908138401792.0000,\n",
      "                                         0.0000],\n",
      "        [                                0.0000,\n",
      "                                         0.0000,\n",
      "                                         0.0000,\n",
      "                                         0.0000,\n",
      "                             -721687281664.0000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3,5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.864479Z",
     "start_time": "2019-05-26T13:40:12.860351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3237, 0.5367, 0.2025],\n",
      "        [0.5787, 0.2415, 0.3374],\n",
      "        [0.5662, 0.9899, 0.5620],\n",
      "        [0.8118, 0.6365, 0.8015],\n",
      "        [0.7641, 0.1177, 0.8615]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.871342Z",
     "start_time": "2019-05-26T13:40:12.865977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5,3, dtype=torch.long)\n",
    "print(x)\n",
    "print(type(x))\n",
    "print(type(x[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construct directly from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.876826Z",
     "start_time": "2019-05-26T13:40:12.873189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 4., 5.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([3,4,5])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.881836Z",
     "start_time": "2019-05-26T13:40:12.878354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construct new tensor based on old one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.888061Z",
     "start_time": "2019-05-26T13:40:12.884216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(3,3, dtype=torch.double)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.895195Z",
     "start_time": "2019-05-26T13:40:12.890665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones_like(x, dtype=torch.int32)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.901006Z",
     "start_time": "2019-05-26T13:40:12.897205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1480, -2.0721,  1.8282],\n",
      "        [ 0.2134, -0.4376,  2.0118],\n",
      "        [ 0.7425,  0.9290, -0.6039]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float32)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.907549Z",
     "start_time": "2019-05-26T13:40:12.903034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0796, 0.2789, 0.9946, 0.8904],\n",
      "         [0.9633, 0.9282, 0.5331, 0.3320],\n",
      "         [0.7257, 0.8744, 0.6534, 0.0860],\n",
      "         [0.6667, 0.4911, 0.2808, 0.0037]],\n",
      "\n",
      "        [[0.8576, 0.4895, 0.1684, 0.8730],\n",
      "         [0.7089, 0.8815, 0.8661, 0.7686],\n",
      "         [0.7680, 0.9903, 0.0249, 0.3507],\n",
      "         [0.8231, 0.9657, 0.6666, 0.5170]],\n",
      "\n",
      "        [[0.9376, 0.6008, 0.8627, 0.0435],\n",
      "         [0.6794, 0.7389, 0.0770, 0.9726],\n",
      "         [0.0746, 0.4947, 0.4803, 0.0536],\n",
      "         [0.1309, 0.1714, 0.9006, 0.0183]]])\n",
      "torch.Size([3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,4,4)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.915326Z",
     "start_time": "2019-05-26T13:40:12.909000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6308, 0.1683, 0.0372],\n",
      "        [0.3490, 0.2137, 0.1213],\n",
      "        [0.5321, 0.4935, 0.6786],\n",
      "        [0.5447, 0.5786, 0.5905],\n",
      "        [0.7402, 0.1833, 0.2643]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1.6308, 1.1683, 1.0372],\n",
      "        [1.3490, 1.2137, 1.1213],\n",
      "        [1.5321, 1.4935, 1.6786],\n",
      "        [1.5447, 1.5786, 1.5905],\n",
      "        [1.7402, 1.1833, 1.2643]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "y = torch.ones(5,3)\n",
    "print(x)\n",
    "print(y)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.920763Z",
     "start_time": "2019-05-26T13:40:12.916640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6308, 1.1683, 1.0372],\n",
      "        [1.3490, 1.2137, 1.1213],\n",
      "        [1.5321, 1.4935, 1.6786],\n",
      "        [1.5447, 1.5786, 1.5905],\n",
      "        [1.7402, 1.1833, 1.2643]])\n"
     ]
    }
   ],
   "source": [
    "# or use torch.add\n",
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output to some variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.927361Z",
     "start_time": "2019-05-26T13:40:12.922493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6308, 1.1683, 1.0372],\n",
      "        [1.3490, 1.2137, 1.1213],\n",
      "        [1.5321, 1.4935, 1.6786],\n",
      "        [1.5447, 1.5786, 1.5905],\n",
      "        [1.7402, 1.1833, 1.2643]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5,3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.930948Z",
     "start_time": "2019-05-26T13:40:12.928749Z"
    }
   },
   "outputs": [],
   "source": [
    "# another way is to add inplace\n",
    "# Any operation that mutates a tensor in-place is post-fixed with an _. \n",
    "# For example: x.copy_(y), x.t_(), will change x.\n",
    "#y.add_(x)\n",
    "#print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get part of tensor. similar to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.936186Z",
     "start_time": "2019-05-26T13:40:12.932640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1683, 0.2137, 0.4935, 0.5786, 0.1833])\n"
     ]
    }
   ],
   "source": [
    "# second column of x\n",
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reshape the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.944452Z",
     "start_time": "2019-05-26T13:40:12.938090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5772, 0.6867, 0.6494, 0.1506],\n",
      "        [0.5549, 0.0668, 0.4300, 0.0382],\n",
      "        [0.2834, 0.0151, 0.5922, 0.8631],\n",
      "        [0.5196, 0.3465, 0.7036, 0.2252]])\n",
      "tensor([[0.5772, 0.6867, 0.6494, 0.1506, 0.5549, 0.0668, 0.4300, 0.0382, 0.2834,\n",
      "         0.0151, 0.5922, 0.8631, 0.5196, 0.3465, 0.7036, 0.2252]])\n",
      "tensor([[0.5772, 0.6867],\n",
      "        [0.6494, 0.1506],\n",
      "        [0.5549, 0.0668],\n",
      "        [0.4300, 0.0382],\n",
      "        [0.2834, 0.0151],\n",
      "        [0.5922, 0.8631],\n",
      "        [0.5196, 0.3465],\n",
      "        [0.7036, 0.2252]])\n",
      "torch.Size([4, 4]) torch.Size([1, 16]) torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,4)\n",
    "y = x.view(1,16)\n",
    "z = x.view(-1, 2) # -1 means the size will be inferred by other dimensions\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the value of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.950011Z",
     "start_time": "2019-05-26T13:40:12.945821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0668)\n",
      "0.06684494018554688\n"
     ]
    }
   ],
   "source": [
    "print(x[1][1])\n",
    "print(x[1][1].item())\n",
    "# print(x.item()) # only one element of tensor can be converted to Python scalars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The torch and numpy will share underlying memory locations, and change one will change the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.955623Z",
     "start_time": "2019-05-26T13:40:12.951806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1,2,3,4])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.963110Z",
     "start_time": "2019-05-26T13:40:12.956994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "y = x.numpy()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.969425Z",
     "start_time": "2019-05-26T13:40:12.964907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3., 4., 5.])\n",
      "[2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "x.add_(1)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.974981Z",
     "start_time": "2019-05-26T13:40:12.971075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y = np.ones(4)\n",
    "x = torch.from_numpy(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.983527Z",
     "start_time": "2019-05-26T13:40:12.979360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2.]\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y = np.add(y, 1) # y is not the same y as before. so y and x are now not the same variable. \n",
    "                 # Pay attention to this!!!!!!\n",
    "print(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.990643Z",
     "start_time": "2019-05-26T13:40:12.986794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 3. 3.]\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "np.add(y, 1, out=y)\n",
    "print(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:12.996737Z",
     "start_time": "2019-05-26T13:40:12.992469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:13.002478Z",
     "start_time": "2019-05-26T13:40:12.998163Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda') # cuda device object\n",
    "    y = torch.ones(3,3, device=device) # assign device to cuda\n",
    "    x = torch.ones(3,3)\n",
    "    x.to(device) # also can use .to(device)\n",
    "    z = x+y\n",
    "    print(z)\n",
    "    print(z.to('cpu', torch.double))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd automatic differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when you set attribute `.requires_grad` to `True`, the pytorch will track the operations, and when you do `.backward()`, it will compute the gradients automatically. You can use `.grad` or `.grad_fn` to get the gradient. `.grad_fn` for function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To un-track the gradients, use `.detach()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when evaluate, you do not need gradient, so use `with torch.no_grad():`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:13.007089Z",
     "start_time": "2019-05-26T13:40:13.004227Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:13.013359Z",
     "start_time": "2019-05-26T13:40:13.009005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3,3, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:13.017840Z",
     "start_time": "2019-05-26T13:40:13.014649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [3., 3., 3.]], grad_fn=<AddBackward>)\n",
      "<AddBackward object at 0x115915c50>\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:13.024743Z",
     "start_time": "2019-05-26T13:40:13.019328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27., 27.],\n",
      "        [27., 27., 27.],\n",
      "        [27., 27., 27.]], grad_fn=<MulBackward>) tensor(27., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z = y*y*3\n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:13.029827Z",
     "start_time": "2019-05-26T13:40:13.026050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3,3)\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:13.036397Z",
     "start_time": "2019-05-26T13:40:13.031621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,3, requires_grad=True)\n",
    "y = x+2\n",
    "z = y*y*3\n",
    "out = z.mean()\n",
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:13.041694Z",
     "start_time": "2019-05-26T13:40:13.037670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section we will use how to create a neural network using `torch.nn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a typical training procedure, there are probably these steps:\n",
    "* define the network, initial the weights\n",
    "* iterate over a dataset of inputs\n",
    "* process input through the network\n",
    "* compute the loss\n",
    "* propagate gradients back into the network's weights\n",
    "* update weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define a simple convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alexnet](./mnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:13.053247Z",
     "start_time": "2019-05-26T13:40:13.043199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    # 1. the \"__init__\" defines what layers you want to use\n",
    "    # 2. the \"forward\" defines the structure of the network, namely how the data flows\n",
    "    # 3. the pytorch will do the gradient automatically, generally you do not have to define\n",
    "    # backward path.\n",
    "    # 4. and other helper fuctions as needed.\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # kernel, input 1, output channel 6, kernel size 5\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # feed forward layer\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # max pooling over 2*2 window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        # if max pooling window size is square, can specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets print the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:13.057737Z",
     "start_time": "2019-05-26T13:40:13.054603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size()) # conv1's weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's try a random input.\n",
    "\n",
    "From the network shown above, we know the input size is 32*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:13.070810Z",
     "start_time": "2019-05-26T13:40:13.059185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0814,  0.1121, -0.0654, -0.0244, -0.0667, -0.0930,  0.0211,  0.0687,\n",
      "          0.1011, -0.0802]], grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input_pic = torch.randn(1,1,32,32)\n",
    "out = net(input_pic)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero the gradient buffers of all parameters and backprops with random gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:13.078545Z",
     "start_time": "2019-05-26T13:40:13.072169Z"
    }
   },
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.nn` only supports mini-batches. The entire `torch.nn` package only supports inputs that are a mini-batch of samples, and not a single sample.\n",
    "\n",
    "For example, `nn.Conv2d` will take in a 4D Tensor of `nSamples x nChannels x Height x Width`.\n",
    "\n",
    "If you have a single sample, just use `input.unsqueeze(0)` to add a fake batch dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several loss functions under the `nn` package. For example, `nn.MSELoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:13.085645Z",
     "start_time": "2019-05-26T13:40:13.079793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2324, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "out = net(input_pic)\n",
    "target = torch.randn(10)\n",
    "target = target.view(1, -1) # make it the same shape as out\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(out, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "      -> view -> linear -> relu -> linear -> relu -> linear\n",
    "      -> MSELoss\n",
    "      -> loss\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:13.091269Z",
     "start_time": "2019-05-26T13:40:13.087251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x11595fc88>\n",
      "<ThAddmmBackward object at 0x11595fcc0>\n",
      "<ExpandBackward object at 0x11595fc88>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we shall call `loss.backward()` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You need to clean the existing gradients though, else gradients will be accumulated to existing gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:13.098357Z",
     "start_time": "2019-05-26T13:40:13.092539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conc1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conc1.bias.grad after backward\n",
      "tensor([-0.0087,  0.0032,  0.0001, -0.0156, -0.0214, -0.0105])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad() # clean the gradient buffer\n",
    "\n",
    "print('conc1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "print('conc1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Stochastic Gradient Descent(SGD):\n",
    "\n",
    "$weight = weight - learning\\_rate * gradient$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:13.102980Z",
     "start_time": "2019-05-26T13:40:13.099750Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you can use update rules built in torch, such as SGD, Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:40:13.109013Z",
     "start_time": "2019-05-26T13:40:13.104378Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# in your training loop\n",
    "optimizer.zero_grad() # really important to clear buffer before backward()\n",
    "output = net(input_pic)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step() # does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are dealing with image, text, audio or video data, you can use standard `python` packages that load data into a numpy array, then convert array to `torch.*Tensor`.\n",
    "\n",
    "* For images, packages such as Pillow, OpenCV\n",
    "* For audio, packages such as scipy and librosa\n",
    "* For text, either raw python or NLTK and SpaCy are useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For vision, torch create a package called `torchvision`, that has data loaders for commom datasets such as:\n",
    "\n",
    "* ImageNet\n",
    "* CIFAR10\n",
    "* MNIST\n",
    "\n",
    "etc. \n",
    "\n",
    "Also, torchvision and torch has data transformers for images, `torchvision.datasets` and `torch.utils.data.DataLoader`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this official tutorial, they use CIFAR10 dataset.\n",
    "\n",
    "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "\n",
    "![cifar10](./cifar10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an image classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using torchvision\n",
    "2. Define a Convolutional Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading and normalizing CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use torchvision to load CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:41:29.854368Z",
     "start_time": "2019-05-26T13:41:29.851178Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:47:00.421827Z",
     "start_time": "2019-05-26T13:46:44.109291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "[transforms.ToTensor(),\n",
    "transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, \n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, \n",
    "                                        download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, \n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:47:08.869924Z",
     "start_time": "2019-05-26T13:47:08.866110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
     ]
    }
   ],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:47:30.526760Z",
     "start_time": "2019-05-26T13:47:30.386637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60min_start.ipynb cifar10.png       \u001b[1m\u001b[36mdata\u001b[m\u001b[m              mnist.png\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:53:11.239757Z",
     "start_time": "2019-05-26T13:53:11.033086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plane plane plane   cat\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 # undo normalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()\n",
    "    \n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "print(' '.join(\"%5s\" % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
