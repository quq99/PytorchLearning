{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is:\n",
    "1. understand basic tensor in Pytorch and understand neural networks\n",
    "2. train a simple neural network using Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. a replacement of numpy\n",
    "2. a deep learning platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.692606Z",
     "start_time": "2019-04-14T00:12:50.166298Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construct matrix uninitialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.712176Z",
     "start_time": "2019-04-14T00:12:50.694201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000, -0.0000, -0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3,5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.718860Z",
     "start_time": "2019-04-14T00:12:50.714487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2864, 0.4463, 0.8009],\n",
      "        [0.4186, 0.1173, 0.1224],\n",
      "        [0.2332, 0.3796, 0.3635],\n",
      "        [0.6057, 0.0508, 0.8237],\n",
      "        [0.0692, 0.7585, 0.8197]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.726909Z",
     "start_time": "2019-04-14T00:12:50.721803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5,3, dtype=torch.long)\n",
    "print(x)\n",
    "print(type(x))\n",
    "print(type(x[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construct directly from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.733237Z",
     "start_time": "2019-04-14T00:12:50.728966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 4., 5.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([3,4,5])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.738419Z",
     "start_time": "2019-04-14T00:12:50.735257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construct new tensor based on old one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.744857Z",
     "start_time": "2019-04-14T00:12:50.740146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(3,3, dtype=torch.double)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.751048Z",
     "start_time": "2019-04-14T00:12:50.746198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones_like(x, dtype=torch.int32)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.757914Z",
     "start_time": "2019-04-14T00:12:50.752939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0908,  0.3771, -0.5684],\n",
      "        [ 0.2456,  0.4868,  0.6290],\n",
      "        [ 1.5616, -2.8548,  0.2614]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float32)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.764218Z",
     "start_time": "2019-04-14T00:12:50.759249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5597, 0.3814, 0.3743, 0.5852],\n",
      "         [0.3242, 0.0196, 0.9332, 0.0485],\n",
      "         [0.7294, 0.2922, 0.1860, 0.8673],\n",
      "         [0.2162, 0.3669, 0.0297, 0.5610]],\n",
      "\n",
      "        [[0.1883, 0.3718, 0.1807, 0.6414],\n",
      "         [0.9965, 0.5973, 0.1137, 0.3563],\n",
      "         [0.8269, 0.6626, 0.1067, 0.5239],\n",
      "         [0.2682, 0.6338, 0.9908, 0.8159]],\n",
      "\n",
      "        [[0.8661, 0.4879, 0.5275, 0.1209],\n",
      "         [0.5145, 0.7656, 0.2251, 0.6859],\n",
      "         [0.3675, 0.6285, 0.5916, 0.6226],\n",
      "         [0.1560, 0.2315, 0.7378, 0.0149]]])\n",
      "torch.Size([3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,4,4)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.772411Z",
     "start_time": "2019-04-14T00:12:50.766168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5210, 0.3038, 0.2678],\n",
      "        [0.6284, 0.3749, 0.5634],\n",
      "        [0.1286, 0.7155, 0.3982],\n",
      "        [0.7393, 0.5615, 0.1526],\n",
      "        [0.2759, 0.1615, 0.1626]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1.5210, 1.3038, 1.2678],\n",
      "        [1.6284, 1.3749, 1.5634],\n",
      "        [1.1286, 1.7155, 1.3982],\n",
      "        [1.7393, 1.5615, 1.1526],\n",
      "        [1.2759, 1.1615, 1.1626]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "y = torch.ones(5,3)\n",
    "print(x)\n",
    "print(y)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.778556Z",
     "start_time": "2019-04-14T00:12:50.774167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5210, 1.3038, 1.2678],\n",
      "        [1.6284, 1.3749, 1.5634],\n",
      "        [1.1286, 1.7155, 1.3982],\n",
      "        [1.7393, 1.5615, 1.1526],\n",
      "        [1.2759, 1.1615, 1.1626]])\n"
     ]
    }
   ],
   "source": [
    "# or use torch.add\n",
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output to some variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.784614Z",
     "start_time": "2019-04-14T00:12:50.780569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5210, 1.3038, 1.2678],\n",
      "        [1.6284, 1.3749, 1.5634],\n",
      "        [1.1286, 1.7155, 1.3982],\n",
      "        [1.7393, 1.5615, 1.1526],\n",
      "        [1.2759, 1.1615, 1.1626]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5,3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.788656Z",
     "start_time": "2019-04-14T00:12:50.786492Z"
    }
   },
   "outputs": [],
   "source": [
    "# another way is to add inplace\n",
    "# Any operation that mutates a tensor in-place is post-fixed with an _. \n",
    "# For example: x.copy_(y), x.t_(), will change x.\n",
    "#y.add_(x)\n",
    "#print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get part of tensor. similar to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.794970Z",
     "start_time": "2019-04-14T00:12:50.790857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3038, 0.3749, 0.7155, 0.5615, 0.1615])\n"
     ]
    }
   ],
   "source": [
    "# second column of x\n",
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reshape the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.804245Z",
     "start_time": "2019-04-14T00:12:50.797386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2842, 0.7860, 0.5625, 0.4784],\n",
      "        [0.3343, 0.8163, 0.3659, 0.7559],\n",
      "        [0.7444, 0.0327, 0.7979, 0.1698],\n",
      "        [0.9490, 0.9337, 0.4154, 0.1327]])\n",
      "tensor([[0.2842, 0.7860, 0.5625, 0.4784, 0.3343, 0.8163, 0.3659, 0.7559, 0.7444,\n",
      "         0.0327, 0.7979, 0.1698, 0.9490, 0.9337, 0.4154, 0.1327]])\n",
      "tensor([[0.2842, 0.7860],\n",
      "        [0.5625, 0.4784],\n",
      "        [0.3343, 0.8163],\n",
      "        [0.3659, 0.7559],\n",
      "        [0.7444, 0.0327],\n",
      "        [0.7979, 0.1698],\n",
      "        [0.9490, 0.9337],\n",
      "        [0.4154, 0.1327]])\n",
      "torch.Size([4, 4]) torch.Size([1, 16]) torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,4)\n",
    "y = x.view(1,16)\n",
    "z = x.view(-1, 2) # -1 means the size will be inferred by other dimensions\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the value of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.814568Z",
     "start_time": "2019-04-14T00:12:50.810336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8163)\n",
      "0.8163231015205383\n"
     ]
    }
   ],
   "source": [
    "print(x[1][1])\n",
    "print(x[1][1].item())\n",
    "# print(x.item()) # only one element of tensor can be converted to Python scalars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The torch and numpy will share underlying memory locations, and change one will change the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.823082Z",
     "start_time": "2019-04-14T00:12:50.819627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1,2,3,4])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.831053Z",
     "start_time": "2019-04-14T00:12:50.824537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "y = x.numpy()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.836806Z",
     "start_time": "2019-04-14T00:12:50.832895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3., 4., 5.])\n",
      "[2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "x.add_(1)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.842440Z",
     "start_time": "2019-04-14T00:12:50.838528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y = np.ones(4)\n",
    "x = torch.from_numpy(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.847675Z",
     "start_time": "2019-04-14T00:12:50.844204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2.]\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y = np.add(y, 1) # y is not the same y as before. so y and x are now not the same variable. \n",
    "                 # Pay attention to this!!!!!!\n",
    "print(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.853918Z",
     "start_time": "2019-04-14T00:12:50.849472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 3. 3.]\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "np.add(y, 1, out=y)\n",
    "print(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.858990Z",
     "start_time": "2019-04-14T00:12:50.855305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.864740Z",
     "start_time": "2019-04-14T00:12:50.861031Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda') # cuda device object\n",
    "    y = torch.ones(3,3, device=device) # assign device to cuda\n",
    "    x = torch.ones(3,3)\n",
    "    x.to(device) # also can use .to(device)\n",
    "    z = x+y\n",
    "    print(z)\n",
    "    print(z.to('cpu', torch.double))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd automatic differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when you set attribute `.requires_grad` to `True`, the pytorch will track the operations, and when you do `.backward()`, it will compute the gradients automatically. You can use `.grad` or `.grad_fn` to get the gradient. `.grad_fn` for function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To un-track the gradients, use `.detach()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when evaluate, you do not need gradient, so use `with torch.no_grad():`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.868476Z",
     "start_time": "2019-04-14T00:12:50.866387Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.874080Z",
     "start_time": "2019-04-14T00:12:50.870064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3,3, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.879557Z",
     "start_time": "2019-04-14T00:12:50.876051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [3., 3., 3.]], grad_fn=<AddBackward>)\n",
      "<AddBackward object at 0x11f9a3940>\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.887745Z",
     "start_time": "2019-04-14T00:12:50.881737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27., 27.],\n",
      "        [27., 27., 27.],\n",
      "        [27., 27., 27.]], grad_fn=<MulBackward>) tensor(27., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z = y*y*3\n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.892728Z",
     "start_time": "2019-04-14T00:12:50.889611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3,3)\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.899687Z",
     "start_time": "2019-04-14T00:12:50.894444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,3, requires_grad=True)\n",
    "y = x+2\n",
    "z = y*y*3\n",
    "out = z.mean()\n",
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T00:12:50.905438Z",
     "start_time": "2019-04-14T00:12:50.901489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section we will use how to create a neural network using `torch.nn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a typical training procedure, there are probably these steps:\n",
    "* define the network, initial the weights\n",
    "* iterate over a dataset of inputs\n",
    "* process input through the network\n",
    "* compute the loss\n",
    "* propagate gradients back into the network's weights\n",
    "* update weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define a simple convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alexnet](./mnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T19:28:56.070188Z",
     "start_time": "2019-05-19T19:28:56.025604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    # 1. the \"__init__\" defines what layers you want to use\n",
    "    # 2. the \"forward\" defines the structure of the network, namely how the data flows\n",
    "    # 3. the pytorch will do the gradient automatically, generally you do not have to define\n",
    "    # backward path.\n",
    "    # 4. and other helper fuctions as needed.\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # kernel, input 1, output channel 6, kernel size 5\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # feed forward layer\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # max pooling over 2*2 window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        # if max pooling window size is square, can specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets print the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T19:32:20.183129Z",
     "start_time": "2019-05-19T19:32:20.178854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size()) # conv1's weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's try a random input.\n",
    "\n",
    "From the network shown above, we know the input size is 32*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T19:42:28.495343Z",
     "start_time": "2019-05-19T19:42:28.489823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1334, -0.0906, -0.0481, -0.0022, -0.1154,  0.0497,  0.0678,  0.0755,\n",
      "         -0.0473,  0.0222]], grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input_pic = torch.randn(1,1,32,32)\n",
    "out = net(input_pic)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero the gradient buffers of all parameters and backprops with random gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T19:45:37.587843Z",
     "start_time": "2019-05-19T19:45:37.577525Z"
    }
   },
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.nn` only supports mini-batches. The entire `torch.nn` package only supports inputs that are a mini-batch of samples, and not a single sample.\n",
    "\n",
    "For example, `nn.Conv2d` will take in a 4D Tensor of `nSamples x nChannels x Height x Width`.\n",
    "\n",
    "If you have a single sample, just use `input.unsqueeze(0)` to add a fake batch dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several loss functions under the `nn` package. For example, `nn.MSELoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T00:47:25.691194Z",
     "start_time": "2019-05-21T00:47:25.681909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8211, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "out = net(input_pic)\n",
    "target = torch.randn(10)\n",
    "target = target.view(1, -1) # make it the same shape as out\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(out, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "      -> view -> linear -> relu -> linear -> relu -> linear\n",
    "      -> MSELoss\n",
    "      -> loss\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T00:49:52.143081Z",
     "start_time": "2019-05-21T00:49:52.137884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x11e3caa58>\n",
      "<ThAddmmBackward object at 0x11e3ca0f0>\n",
      "<ExpandBackward object at 0x11e3caa58>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we shall call `loss.backward()` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You need to clean the existing gradients though, else gradients will be accumulated to existing gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T21:32:44.966715Z",
     "start_time": "2019-05-25T21:32:44.912636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conc1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conc1.bias.grad after backward\n",
      "tensor([-0.0097,  0.0021, -0.0021, -0.0121,  0.0021,  0.0200])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad() # clean the gradient buffer\n",
    "\n",
    "print('conc1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "print('conc1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Stochastic Gradient Descent(SGD):\n",
    "\n",
    "$weight = weight - learning\\_rate * gradient$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T21:35:07.620079Z",
     "start_time": "2019-05-25T21:35:07.608966Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you can use update rules built in torch, such as SGD, Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T21:40:02.183681Z",
     "start_time": "2019-05-25T21:40:02.177743Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# in your training loop\n",
    "optimizer.zero_grad() # really important to clear buffer before backward()\n",
    "output = net(input_pic)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step() # does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
